import numpy as np
import pandas as pd

# from pathlib import Path
# from colorama import Fore, Style
# from dateutil.parser import parse

from medium.params import *
from medium.ml_logic.data import clean_data, load_json_from_files
from medium.ml_logic.registry import load_model, save_model, save_results, save_preprocessor, load_preprocessor

from medium.ml_logic.model import initialize_model, compile_model, train_model, evaluate_model, implemented_model
from medium.ml_logic.preprocessor import preprocess_features

def preprocess() -> None:
    """
    - Charge les donn√©es brutes depuis les fichiers JSON et CSV
    - Nettoie et pr√©processe les donn√©es
    - Stocke les donn√©es trait√©es
    """
    print("üé¨ main preprocess starting ................\n")

    # Charger les donn√©es JSON
    data = load_json_from_files(X_filepath=DATA_TRAIN, y_filepath=DATA_LOG_RECOMMEND, num_lines=DATA_SIZE)

    # Nettoyer les donn√©es
    data_cleaned = clean_data(data)

    # Pr√©traiter les features
    df_processed, preprocessor = preprocess_features(data_cleaned)

    # Sauvegarder les donn√©es trait√©es localement si necessaire
    df_processed.to_csv(os.path.join(LOCAL_REGISTRY_PATH, "data", f"df_processed_{DATA_SIZE}.csv"), index=False)

    # Sauvegarder le pr√©processeur
    save_preprocessor(preprocessor)

    print("üèÅ main preprocess done \n")

    return None

def train(
        split_ratio: float = 0.2,
        #batch_size=32,
        #patience=3
    ) -> float:
    """
    - Charge les donn√©es pr√©process√©es
    - Entra√Æne le mod√®le sur le dataset
    - Stocke les r√©sultats et les poids du mod√®le

    Return val_mae as a float
    """
    print("üé¨ main train starting ................\n")

    # Charger les donn√©es pr√©process√©es (despuis le csv si sauvegard√©)
    df_processed = pd.read_csv(os.path.join(LOCAL_REGISTRY_PATH, "data", f"df_processed_{DATA_SIZE}.csv"))

    # Cr√©er X et y
    X = df_processed.drop(columns=['log1p_recommends'])
    y = df_processed['log1p_recommends']

    # Split train/validation
    train_length = int(len(df_processed)*(1-split_ratio))
    X_train, X_val = X[:train_length], X[train_length:]
    y_train, y_val = y[:train_length], y[train_length:]

    model = load_model()

    if model is None:
        # Initialiser le mod√®le
        model = initialize_model(model = 'LinearRegression', input_shape=(X_train.shape[1],))

    model = train_model(model=model, X=X_train, y=y_train)

    val_metric = evaluate_model(model=model, X=X_val, y=y_val)

    params = {
        "split_ratio": split_ratio,
        "metric": implemented_model[model.__class__.__name__]['metrics']
    }

    # Save results
    save_results(params=params, metrics=dict(mae=val_metric))

    # Save model
    save_model(model=model)

    print("üèÅ main train() done \n")
    return val_metric


def evaluate(stage: str = "Production") -> float:
    """
    √âvalue la performance du mod√®le sur l'ensemble de validation
    Return metric as a float
    """
    print("üé¨ main evaluate starting ................\n")

    metric =0.0

    print(" üí§ TO DO   !!!!!!!!!!!!!!  \n")


    print("üèÅ main evaluate() done \n")
    return metric


def pred(X_pred: pd.DataFrame = None) -> np.ndarray:
    """
    Fait une pr√©diction using le dernier mod√®le entra√Æn√©
    """
    print("üé¨ pred starting ................\n")

    print("\n‚≠êÔ∏è Use case: predict")

    if X_pred is None:
        # Exemple de donn√©es pour pr√©diction
        # ü´° √† pr√©voir  le webstrapping via URL en focntion de l'avancement
        X_pred = load_json_from_files(X_filepath=DATA_TEST, y_filepath=DATA_TEST_LOG_RECOMMEND, num_lines=DATA_TEST_SIZE)

    model = load_model()
    preprocessor = load_preprocessor()
    print(f"Transform: {model.__class__.__name__}")
    X_processed = preprocessor.transform(X_pred)
    y_pred = model.predict(X_processed)

    # Transformation inverse si n√©cessaire
    # !! expm1   = exp -1
    y_pred_original = np.expm1(y_pred)
    # y_pred_original = np.expm1(y_pred) #  log1p inverse

    print(f"‚≠êÔ∏è Predictions: {y_pred.mean()} ...\n")

    print("üèÅ pred() done \n")
    return y_pred_original

def run_all():
    preprocess()
    train()
    #evaluate()
    #pred()

if __name__ == '__main__':
    # Workflow complet
    preprocess()
    train()
    evaluate()
    pred()
