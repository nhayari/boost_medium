import numpy as np
import pandas as pd

# from pathlib import Path
# from colorama import Fore, Style
# from dateutil.parser import parse

from medium.params import *
from medium.ml_logic.data import clean_data, load_json_from_files
from medium.ml_logic.registry import load_model, save_model, save_results

from medium.ml_logic.model import initialize_model, compile_model, train_model, evaluate_model, implemented_model
from medium.ml_logic.preprocessor import preprocess_features

def preprocess() -> None:
    """
    - Charge les donnÃ©es brutes depuis les fichiers JSON et CSV
    - Nettoie et prÃ©processe les donnÃ©es
    - Stocke les donnÃ©es traitÃ©es
    """
    print("ğŸ¬ main preprocess starting ................\n")

    # Charger les donnÃ©es JSON
    data = load_json_from_files(X_filepath=DATA_TRAIN, y_filepath=DATA_LOG_RECOMMEND, num_lines=DATA_SIZE)

    # Nettoyer les donnÃ©es
    data_cleaned = clean_data(data)

    # PrÃ©traiter les features
    df_processed = preprocess_features(data_cleaned)

    # Sauvegarder les donnÃ©es traitÃ©es localement si necessaire
    df_processed.to_csv(os.path.join(LOCAL_REGISTRY_PATH, "data", f"df_processed_{DATA_SIZE}.csv"), index=False)

    print("ğŸ main preprocess done \n")

    return None

def train(
        split_ratio: float = 0.2,
        #batch_size=32,
        #patience=3
    ) -> float:
    """
    - Charge les donnÃ©es prÃ©processÃ©es
    - EntraÃ®ne le modÃ¨le sur le dataset
    - Stocke les rÃ©sultats et les poids du modÃ¨le

    Return val_mae as a float
    """
    print("ğŸ¬ main train starting ................\n")

    # Charger les donnÃ©es prÃ©processÃ©es (despuis le csv si sauvegardÃ©)
    df_processed = pd.read_csv(os.path.join(LOCAL_REGISTRY_PATH, "data", f"df_processed_{DATA_SIZE}.csv"))

    # CrÃ©er X et y
    X = df_processed.drop(columns=['log1p_recommends'])
    y = df_processed['log1p_recommends']

    # Split train/validation
    train_length = int(len(df_processed)*(1-split_ratio))
    X_train, X_val = X[:train_length], X[train_length:]
    y_train, y_val = y[:train_length], y[train_length:]

    model = load_model()

    if model is None:
        # Initialiser le modÃ¨le
        model = initialize_model(model = 'LinearRegression', input_shape=(X_train.shape[1],))

    model = train_model(model=model, X=X_train, y=y_train)

    val_metric = evaluate_model(model=model, X=X_val, y=y_val)

    params = {
        "split_ratio": split_ratio,
        "metric": implemented_model[model.__class__.__name__]['metrics']
    }

    # Save results
    save_results(params=params, metrics=dict(mae=val_metric))

    # Save model
    save_model(model=model)

    print("ğŸ main train() done \n")
    return val_metric


def evaluate(stage: str = "Production") -> float:
    """
    Ã‰value la performance du modÃ¨le sur l'ensemble de validation
    Return metric as a float
    """
    print("ğŸ¬ main evaluate starting ................\n")

    metric =0.0

    print(" ğŸ’¤ TO DO   !!!!!!!!!!!!!!  \n")


    print("ğŸ main evaluate() done \n")
    return metric


def pred(X_pred: pd.DataFrame = None) -> np.ndarray:
    """
    Fait une prÃ©diction using le dernier modÃ¨le entraÃ®nÃ©
    """
    print("ğŸ¬ pred starting ................\n")

    metric =0.0

    print(" ğŸ’¤ TO DO   !!!!!!!!!!!!!! \n")

    print("\nâ­ï¸ Use case: predict")

    if X_pred is None:
        # Exemple de donnÃ©es pour prÃ©diction
        # ğŸ«¡ Ã  prÃ©voir  le webstrapping via URL en focntion de l'avancement
        X_pred = pd.DataFrame({
            'content': ['This is a sample article about machine learning and data science.'],
            'title': ['Machine learning'],
            'author': ['Data Scientist'],
            'published': ['2025-08-26T14:06:00Z']
        })

    model = None  #load_model()

    X_processed =None
    # y_pred = model.predict(X_processed)

    # Transformation inverse si nÃ©cessaire
    # !! expm1   = exp -1
    y_pred_original = None
    # y_pred_original = np.expm1(y_pred) #  log1p inverse

    print("ğŸ pred() done \n")
    return y_pred_original

def run_all():
    preprocess()
    train()
    #evaluate()
    #pred()

if __name__ == '__main__':
    # Workflow complet
    preprocess()
    train()
    evaluate()
    pred()
